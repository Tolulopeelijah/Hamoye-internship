{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06f29d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4806114c",
   "metadata": {},
   "source": [
    "## 1\n",
    "In a binary classification task, you are working on a medical diagnosis model to detect a rare disease. False negatives are six times costlier than false positives. After training four different models, you want to choose the one that minimizes the business cost while meeting specific criteria.\n",
    "\n",
    "Your evaluation criteria are as follows:\n",
    "\n",
    "Must have a precision of at least 90%. Must have a false negative rate of 5% or less. Must minimize business costs. After creating each binary classification model, you generated the corresponding confusion matrix. Which confusion matrix represents the model that satisfies the requirements?\n",
    "\n",
    "Options TN = 97%, FP = 3%, FN = 1%, TP = 99%\n",
    "\n",
    "TN = 99.5%, FP = 0.5%, FN = 7%, TP = 93%\n",
    "\n",
    "TN = 90%, FP = 10%, FN = 3%, TP = 97%\n",
    "\n",
    "TN = 98%, FP = 2%, FN = 5%, TP = 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01713a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall precision false positive rate\n",
      "99.0 97.05882352941177 3.0\n",
      "93.0 99.46524064171123 0.5\n",
      "97.0 90.65420560747664 10.0\n",
      "95.0 97.9381443298969 2.0\n",
      "TN = 97%, FP = 3%, FN = 1%, TP = 99%\n"
     ]
    }
   ],
   "source": [
    "matrix = [{'TN':97, 'FP':3, 'FN':1, 'TP':99},\n",
    "{'TN':99.5, 'FP':0.5, 'FN':7, 'TP':93},\n",
    "{'TN':90, 'FP':10, 'FN':3, 'TP':97},\n",
    "{'TN':98, 'FP':2, 'FN':5, 'TP':95}]\n",
    "print('recall precision false positive rate')\n",
    "for i in matrix:\n",
    "    recall = i['TP']/(i['TP'] + i['FN'])*100\n",
    "    precision = i['TP']/(i['TP'] + i['FP'])*100\n",
    "    false_pos_rate = i['FP']/(i['TN'] + i['FP'])*100\n",
    "    print(recall, precision,  false_pos_rate)\n",
    "    \n",
    "#since the best combination that satisfy the condition is a\n",
    "print('TN = 97%, FP = 3%, FN = 1%, TP = 99%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08db49a",
   "metadata": {},
   "source": [
    "## 2\n",
    "Which of the following machine learning algorithms is unsupervised?\n",
    "\n",
    "Options K-means clustering\n",
    "\n",
    "Random Forest\n",
    "\n",
    "Support vector machines\n",
    "\n",
    "K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86d3f3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-nearest neighbor\n"
     ]
    }
   ],
   "source": [
    "print('K-nearest neighbor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd0f09",
   "metadata": {},
   "source": [
    "## 3\n",
    "You are working on a spam classification system using regularized logistic regression. “Spam” is a positive class (y = 1) and “not spam” is the negative class (y = 0). You have trained your classifier and there are n = 1700 examples in the test set. The confusion matrix of predicted class vs. actual class is:\n",
    "\n",
    "What is the F1 score of this classifier?\n",
    "\n",
    "Options 0.9093\n",
    "\n",
    "1.66387\n",
    "\n",
    "0.8440\n",
    "\n",
    "0.98571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62d44ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9093\n"
     ]
    }
   ],
   "source": [
    "print(0.9093)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8e9f3",
   "metadata": {},
   "source": [
    "## 4\n",
    "Sarah is training a machine learning model for fraud detection. She notices that both the training and test errors are high and close to each other. What issue is she likely facing?\n",
    "\n",
    "Options Exploding gradient\n",
    "\n",
    "Underfitting\n",
    "\n",
    "High Bias\n",
    "\n",
    "Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e5a1638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underfitting\n",
      "High Bias\n"
     ]
    }
   ],
   "source": [
    "print('Underfitting')\n",
    "print('High Bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a4d56",
   "metadata": {},
   "source": [
    "## 5\n",
    "Which of the following metrics is commonly used for evaluating the performance of a classification model, especially when dealing with imbalanced datasets?\n",
    "\n",
    "Options Mean Absolute Error\n",
    "\n",
    "Root Mean Square Error\n",
    "\n",
    "R-squared\n",
    "\n",
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5094a47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision\n"
     ]
    }
   ],
   "source": [
    "print('Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0964b4",
   "metadata": {},
   "source": [
    "## 6\n",
    "Why is bagging often used in ensemble methods like Random Forest, instead of using a single decision tree?\n",
    "\n",
    "Options To prevent overfitting\n",
    "\n",
    "To ensure high bias\n",
    "\n",
    "To reduce variance in predictions\n",
    "\n",
    "To make the model computationally efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc1d1cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To prevent overfitting\n"
     ]
    }
   ],
   "source": [
    "print('To prevent overfitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263baf12",
   "metadata": {},
   "source": [
    "## 7\n",
    "Suppose you have a classifier that predicts whether emails are spam or not. In this case, the cost of classifying a legitimate email as spam and potentially causing users to miss important emails is higher than the cost of marking some spam emails as legitimate. Which metric should we use to evaluate this classifier?\n",
    "\n",
    "Options Recall\n",
    "\n",
    "Specificity\n",
    "\n",
    "Precision\n",
    "\n",
    "F1 Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a85641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision\n",
      "F1 Score\n"
     ]
    }
   ],
   "source": [
    "print('Precision')\n",
    "print('F1 Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3196b95",
   "metadata": {},
   "source": [
    "## 8\n",
    "A financial institution is developing a credit scoring model to predict whether an applicant is likely to default on a loan. The training data contains 10,000 negative instances (applicants who did not default) and only 200 positive instances (applicants who defaulted). The resulting model has a relatively low accuracy, and both precision and recall are important for this application.\n",
    "\n",
    "Which steps could be taken to potentially improve the model's performance? (SELECT ALL APPLICABLE CHOICES)\n",
    "\n",
    "Options Use Boosting algorithm\n",
    "\n",
    "Over-sample instances from the negative (non-default) class\n",
    "\n",
    "Collect more data for the positive case\n",
    "\n",
    "Use Bagging method\n",
    "\n",
    "Under-sample instances from the positive (default) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d491bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options Use Boosting algorithm\n",
      "Collect more data for the positive case\n"
     ]
    }
   ],
   "source": [
    "print('Options Use Boosting algorithm')\n",
    "print('Collect more data for the positive case')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c47e561",
   "metadata": {},
   "source": [
    "## 9\n",
    "You are developing a machine learning model to predict housing prices based on various tabular features such as the number of bedrooms, square footage, neighborhood, and year built. How should you preprocess the tabular feature data?\n",
    "\n",
    "SELECT ALL APPLICABLE OPTIONS\n",
    "\n",
    "Options Min-Max scaling\n",
    "\n",
    "Integer values\n",
    "\n",
    "One-hot encoding\n",
    "\n",
    "Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9e594ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max scaling\n"
     ]
    }
   ],
   "source": [
    "print('Min-Max scaling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e63dd",
   "metadata": {},
   "source": [
    "## 10\n",
    "You're working on a binary classification task, to classify if an image contains a cat (\"1\") or doesn't contain a cat (\"0\"). What loss would you choose to minimize in order to train a model?\n",
    "\n",
    "Options Hinge Loss\n",
    "\n",
    "Mean Absolute Error Loss\n",
    "\n",
    "Binary Cross-Entropy Loss\n",
    "\n",
    "Mean Squared Error Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93d7a166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross-Entropy Loss\n"
     ]
    }
   ],
   "source": [
    "print('Binary Cross-Entropy Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd9e312",
   "metadata": {},
   "source": [
    "## 11\n",
    "\n",
    "You are building a classifier, and the model tends to overfit the training data while having poor generalization to the test data. Which technique would you use to address this issue?\n",
    "\n",
    "Options Bagging\n",
    "\n",
    "Boosting\n",
    "\n",
    "Decision Trees\n",
    "\n",
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23b1a278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging\n",
      "Boosting\n"
     ]
    }
   ],
   "source": [
    "print('Bagging')\n",
    "print('Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ec183e",
   "metadata": {},
   "source": [
    "## 12\n",
    "A random forest classifier was used to classify handwritten digits 0-9 into the numbers they were intended to represent. The confusion matrix below was generated from the results. Based on the matrix, which number was predicted with the highest accuracy?\n",
    "\n",
    "Options 8\n",
    "\n",
    "4\n",
    "\n",
    "9\n",
    "\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24dbc8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90b53d",
   "metadata": {},
   "source": [
    "## 13\n",
    "The ROC curve above was generated from a classification algorithm. What can we say about this classifier?\n",
    "\n",
    "Options It is suitable for the classification task\n",
    "\n",
    "The Area under the Curve is close to 0.5\n",
    "\n",
    "The model is better than random chance\n",
    "\n",
    "The model has good discrimination ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f05d7e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Area under the Curve is close to 0.5\n"
     ]
    }
   ],
   "source": [
    "print('The Area under the Curve is close to 0.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0da2c",
   "metadata": {},
   "source": [
    "## 14\n",
    "What is the accuracy on the test set using the random forest classifier?\n",
    "\n",
    "Options 0.9095\n",
    "\n",
    "0.8913\n",
    "\n",
    "0.7913\n",
    "\n",
    "0.9295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4063f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a267918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "670bb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_space(i):\n",
    "    if len(i.strip()) == 0:\n",
    "        return 0\n",
    "    else: return float(i)\n",
    "\n",
    "\n",
    "train['TotalCharges'] = train['TotalCharges'].apply(replace_space)\n",
    "train.drop(['customerID'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d79f8d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'SeniorCitizen']\n",
      "['tenure', 'MonthlyCharges', 'TotalCharges']\n"
     ]
    }
   ],
   "source": [
    "categorical, numerical = [], []\n",
    "for i in train.columns:\n",
    "    if train[i].dtype == 'O':\n",
    "        categorical.append(i)\n",
    "    else:\n",
    "        numerical.append(i)\n",
    "categorical.pop(categorical.index('Churn'))\n",
    "categorical.append(numerical.pop(numerical.index('SeniorCitizen')))\n",
    "print(categorical)\n",
    "print(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec4a538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "train[['tenure', 'MonthlyCharges', 'TotalCharges']] = ss.fit_transform(train[['tenure', 'MonthlyCharges', 'TotalCharges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6ffe9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "en = OneHotEncoder(sparse = False)\n",
    "le = LabelEncoder()\n",
    "train.Churn = le.fit_transform(train['Churn'])\n",
    "encoded = en.fit_transform(train[categorical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70553c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_df = pd.DataFrame(encoded, columns = en.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91e9376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = pd.concat([train, encode_df], axis = 1)\n",
    "# pd.merge(train, objs, how='outer', on=index)\n",
    "train_en.drop(categorical, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15a85157",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_en.pop('Churn')\n",
    "X = train_en\n",
    "X_train, X_test,  y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41d9c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7913413768630234\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(random_state=1)\n",
    "model1.fit(X_train, y_train)\n",
    "prediction1 = model1.predict(X_test)\n",
    "print(f'accuracy score: {accuracy_score(prediction1, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae88b618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n"
     ]
    }
   ],
   "source": [
    "print('c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde32d1",
   "metadata": {},
   "source": [
    "## 15\n",
    "What is the accuracy on the test set using the xgboost classifier?\n",
    "\n",
    "Options 0.7934\n",
    "\n",
    "0.9295\n",
    "\n",
    "0.7774\n",
    "\n",
    "0.9195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a4a874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b23b69dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7877927608232789\n"
     ]
    }
   ],
   "source": [
    "model = xgboost.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "print(f'accuracy score: {accuracy_score(prediction, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57254532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "#closes answer\n",
    "print('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e222b49d",
   "metadata": {},
   "source": [
    "## 16\n",
    "What is the accuracy on the test set using the LGBM classifier?\n",
    "\n",
    "Options 0.8034\n",
    "\n",
    "0.9465\n",
    "\n",
    "0.9185\n",
    "\n",
    "0.9375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18b1daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "470c12f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8133427963094393\n"
     ]
    }
   ],
   "source": [
    "model = lightgbm.LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "print(f'accuracy score: {accuracy_score(prediction, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bb13374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print('a') #closest answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e9c71",
   "metadata": {},
   "source": [
    "## 17\n",
    "To improve the Extra Trees Classifier, you will use the following parameters (number of estimators, minimum number of samples, minimum number of samples for leaf node and the number of features to consider when looking for the best split) for the hyperparameter grid needed to run a Randomized Cross Validation Search (RandomizedSearchCV).\n",
    "\n",
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "\n",
    "               'min_samples_split': min_samples_split,\n",
    "\n",
    "               'max_features': max_features}\n",
    "Using the ExtraTreesClassifier as your estimator with cv=5, n_iter=10, scoring = 'accuracy', n_jobs = -1, verbose = 1 and random_state = 1. What are the best hyperparameters from the randomized search CV?\n",
    "\n",
    "Options N_estimators = 500 , min_samples_split = 2 , min_samples_leaf = 8, max_features = ‘log2‘\n",
    "\n",
    "N_estimators = 300 , min_samples_split = 5 , min_samples_leaf = 6, max_features = ‘auto’\n",
    "\n",
    "N_estimators = 1000 , min_samples_split = 9 , min_samples_leaf = 8, max_features = None\n",
    "\n",
    "N_estimators = 1000 , min_samples_split = 2 , min_samples_leaf = 8, max_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b40904d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00c1bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65ca0e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;,\n",
       "                                                         None],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6, 8],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 5, 7, 9],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100, 300, 500,\n",
       "                                                         1000]},\n",
       "                   random_state=1, scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;,\n",
       "                                                         None],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6, 8],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 5, 7, 9],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100, 300, 500,\n",
       "                                                         1000]},\n",
       "                   random_state=1, scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'max_features': ['auto', 'sqrt', 'log2',\n",
       "                                                         None],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [2, 3, 5, 7, 9],\n",
       "                                        'n_estimators': [50, 100, 300, 500,\n",
       "                                                         1000]},\n",
       "                   random_state=1, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf =ExtraTreesClassifier()\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=hyperparameter_grid, cv=5, n_iter=10, \n",
    "                                   scoring = 'accuracy', n_jobs=-1, verbose = 1, random_state=1)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b0a0625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ad3a6c",
   "metadata": {},
   "source": [
    "## 18\n",
    "Train a new ExtraTreesClassifier Model with the new Hyperparameters from the RandomizedSearchCV (with random_state = 1). Is the accuracy of the new optimal model higher or lower than the initial ExtraTreesClassifier model with no hyperparameter tuning?\n",
    "\n",
    "Options No change\n",
    "\n",
    "Lower\n",
    "\n",
    "Higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e80ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)\n",
    "prediction = random_search.predict(X_test)\n",
    "prediction2 = rf.predict(X_test)\n",
    "print(f'accuracy score: {accuracy_score(prediction, y_test)}')\n",
    "print(f'accuracy score: {accuracy_score(prediction2, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf29406",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('higher')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448241c",
   "metadata": {},
   "source": [
    "## 19\n",
    "What other hyperparameters can be tuned for ExtraTreeClassifer?\n",
    "\n",
    "Options min_child_weight\n",
    "\n",
    "A, B and C\n",
    "\n",
    "min_weight_fraction_leaf\n",
    "\n",
    "max_leaf_nodes\n",
    "\n",
    "Both B and C\n",
    "\n",
    "Both A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('A, B and C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d324e",
   "metadata": {},
   "source": [
    "## 20\n",
    "Find the feature importance using the optimal ExtraTreesClassifier model. Which features are the two most important respectively?\n",
    "\n",
    "Options Contract_Month-to-month, tenure\n",
    "\n",
    "gender_Female, gender_Male\n",
    "\n",
    "TotalCharges, MonthlyCharges\n",
    "\n",
    "DeviceProtection_No, OnlineBackup_Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_param_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211faec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
